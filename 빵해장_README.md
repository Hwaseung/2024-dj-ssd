# *빵해장* README.md 개요
- 해당  파일에서는 *빵해장* 팀이 제출한 파일에 대해 설명할 예정
- 색인 순서 : [1. ~ 5.] > [1-1 ~ 5-4] > [(1) ~ (8)] > [① ~ ③]


# 목차 : **아래 순서대로 파일을 살펴볼 것을 적극 권장**
[1.빵해장_전처리완료데이터_정의서.xlsx](#1.-빵해장_전처리완료데이터_컬럼-정의서.xlsx)  
[2.빵해장_데모영상.mp4](#2.빵해장_데모영상.mp4)  
[3.빵해장_notebooks.ipynb](#3.빵해장_notebooks.ipynb)  
[4.빵해장_이동경로 및 소비패턴 파일_컬럼 정의서.xlsx](#4.-빵해장_이동경로-및-소비패턴-파일_컬럼-정의서.xlsx)  
[5.빵해장_자유분석.pdf](#5.-빵해장_자유분석.pdff)  
[6.figures](#6.-figures)  


# 1.빵해장_전처리완료데이터_컬럼 정의서.xlsx
## sheet1
- 데이터셋명 : 유동인구
- 파일명 : 유동인구_완료.csv
- 순번 : 컬럼 정의 순서
- 속성 : 해당 데이터의 컬럼명
- 설명 : 데이터 컬럼에 대한 설명
- 값 범위 혹은 범주 : 각각 컬럼이 가지는 범위 혹은 범주
- 원본 / 파생 : 해당 데이터가 원본 데이터인지 혹은 원본 데이터에서 파생된 데이터인지
- 파생 방법 : 파생된 데이터라면, 어떤 원본 데이터에서 파생되었는지와 파생된 방법

</br>

## sheet2
- 데이터셋명 : 카드매출_가맹점
- 파일명 : 카드매출(가맹점)_전처리_완료.csv
- 순번 : 컬럼 정의 순서
- 속성 : 해당 데이터의 컬럼명
- 설명 : 데이터 컬럼에 대한 설명
- 값 범위 혹은 범주 : 각각 컬럼이 가지는 범위 혹은 범주
- 원본 / 파생 : 해당 데이터가 원본 데이터인지 혹은 원본 데이터에서 파생된 데이터인지
- 파생 방법 : 파생된 데이터라면, 어떤 원본 데이터에서 파생되었는지와 파생된 방법

</br>

## sheet3
- 데이터셋명 : 카드매출_유입고객
- 파일명 : 카드매출(유입고객)_전처리_완료.csv
- 순번 : 컬럼 정의 순서
- 속성 : 해당 데이터의 컬럼명
- 설명 : 데이터 컬럼에 대한 설명
- 값 범위 혹은 범주 : 각각 컬럼이 가지는 범위 혹은 범주
- 원본 / 파생 : 해당 데이터가 원본 데이터인지 혹은 원본 데이터에서 파생된 데이터인지
- 파생 방법 : 파생된 데이터라면, 어떤 원본 데이터에서 파생되었는지와 파생된 방법

</br>

# 2.빵해장_데모영상.mp4
- 첨부한 빵해장_데모영상.mp4 참고

</br>

# 3.빵해장_notebooks.ipynb
해당 파일의 색인 순서와 동일하게 작성

## 0 data & packages
### 0-0 코드를 돌린 환경에 대해 정의
(1) 컴퓨터 환경  
(2) CPU 코어 수  
(3) 주피터 노트북 버전  
(4) 파이썬 버전

---
### 0-1 패키지를 설치 & 불러오기
**(1) 패키지 설치**  
- holidays : 공휴일에 대한 정보를 담고 있는 패키지
- pyproj : 지리 좌표계 변환을 수행하는 패키지
- numba : Python 코드에서 빠른 속도의 JIT(Just-In-Time) 컴파일을 제공하여 수치 연산을 최적화하는 패키지
- geopy : 지리적 좌표의 변환, 거리 계산, 및 지오코딩(주소 ↔ 좌표)을 지원하는 Python 라이브러리
- joblib : 병렬 처리와 객체 직렬화(저장 및 로드)를 효율적으로 지원하는 Python 라이브러리

</br>

**(2) 패키지 불러오기**
- 파이썬에 내장되어있는 패키지 로드 : os, pandas, numpy, matplotlib.pyplot, seaborn, warnings, time
- 앞서 (1)에서 설치한 패키지 및 클래스 로드 : holidays, Proj, Transformer (이상 pyproj), parallel, delayed (이상 joblib), njit (이상 numba)

</br>

**(3) **!!!필수!!! path에 데이터 경로 지정****
- 이 부분에 데이터를 불러오거나 데이터를 저장할 path를 지정

---
### 0-2 제공된 데이터, 외부 데이터 등 사용된 데이터 불러오기
**(1) 제공된 데이터 - main**
- 제공된 데이터 중 주요한 데이터
  - 유동인구
  - 카드매출 (cell id별)
  - 카드매출 (지역별 업종 유입고객)

- **데이터명은 아래와 같이 간소화하여 사용**
  - 유동인구 → 유동인구
  - 카드매출 (cell id별) → 카드매출_가맹점
  - 카드매출 (지역별 업종 유입고객) → 카드매출_유입고객  
  
- 제공된 데이터는 모두 1개월 단위씩 나눠져있기 때문에 이를 한 데이터로 합치기  

</br>

**(2) 제공된 데이터 - sub**
- 제공된 데이터 중 (1)에서 언급한 main data를 보조하는 데이터
  - 국토지리정보원_국토조사_(격자)500M.csv
  - 상가(상권)정보_업종분류.xlsx

</br>

**(3) 외부 데이터**
- **행정동 데이터** : 행정동 코드에 맞는 행정동명 찾을 때 활용
  - *행정안정부 > 행정기관(행정동) 및 관할구역(법정동) 변경내역(2024.8.1. 시행)* 의 ***KIKcd_H.20240801.xlsx (이하 행정동 데이터)*** 활용
  - 출처 : https://www.mois.go.kr/frt/bbs/type001/commonSelectBoardArticle.do?bbsId=BBSMSTR_000000000052&nttId=111209 
- **한국표준산업분류10차** : 업종 분류 코드에 맞는 항목명 찾을 때 활용
  - *카드매출_컬럼정의서* 에 나와있는 것처럼 ***통계청 한국표준산업분류10차*** 를 사용
  - 출처 : http://ecosmart.kaist.ac.kr/bbs/board.php?bo_table=menu3_1&wr_id=1 


---
## 1 데이터 전처리
### 1-1 유동인구
#### (1) id
##### ① id와 (x, y) 조합이 일대일대응되는지 확인
- *유동인구 정의서* 에서 id는 셀id라고 명시되어있음. 즉, 50m X 50m 셀에 각각 번호를 부여한 것
- 이때 한 id에 하나의 (x, y) 조합이 존재하는지, 즉 50m X 50m 셀에 대한 대표위치가 모든 시간대에 하나로 정해져있는지 확인
</br>

1) 데이터에서 *x, y, id*를 추출  
2) 한 행에 존재하는 *x, y*를 하나의 조합으로 묶어 리스트에 저장한 후 *x_y*라는 컬럼 추가  
3) *id, x_y* 각각 고유값의 개수 확인  
→ 이와 같은 과정으로 id와 (x, y) 조합이 일대일대응됨을 확인  
→ 이후 성심당 위치를 찾고 이동경로를 분석할 때, x, y 혹은 위도, 경도 값으로 인덱싱하지 않고 간편하게 id로 인덱싱하면 됨 


</br>

#### (2) 행정동 코드
- 고유값을 확인한 결과, 모두 대전광역시 중구의 행정동 코드
  ```
  30140740, 30140690, 30140700, 30140730, 30140710, 30140680,
  30140655, 30140670, 30140720, 30140550, 30140560, 30140535,
  30140630, 30140575, 30140640, 30140605, 30140620
  ```
</br>

##### ① 행정동명 컬럼 추가
- *유동인구 > admi_cd* 는 숫자형으로 되어있어 어떤 행정동인지 직관적으로 알아보기가 쉽지 않음
- 따라서 행정동 코드와 그에 해당하는 행정동명을 포함하고 있는 **외부 데이터인 행정동 데이터*** 를 활용하여 *유동인구 > admi_cd*에 맵핑
</br>

1) *행정동 데이터* 중 **시도명이 대전광역시이고 시군구명이 중구**인 데이터만 남기기  
2) *유동인구 > admi_cd*의 고유값(행정동 코드)을 리스트에 저장  
3) 리스트에 있는 행정동 코드를 필터링된 *행정동 데이터*에 맵핑하여 행정동 코드별로 대응되는 행정동명 추출  
4) 행정동 코드와 행정동명을 딕셔너리로 만든 후 *유동인구 > admi_cd*에 맵핑하여 *유동인구 > 행정동명* 컬럼 생성

</br>

#### (3) x, y 좌표
- KT에서 사용한 KATECH 좌표를 경위도로 변환
- pyproj > Proj, Transformer 사용
</br>

1) 다음과 같은 << x, y → 경위도 >> 변환 함수를 정의
  ```
  katech_proj = Proj(
      "+proj=tmerc +lat_0=38 +lon_0=128 +k=0.9999 +x_0=400000 +y_0=600000 +ellps=bessel "
      "+towgs84=-115.80,474.99,674.11,1.16,-2.31,-1.63,6.43"
  )
  
  # Define the WGS84 projection
  wgs84_proj = Proj(proj="latlong", datum="WGS84")
  
  # Create a Transformer object for the conversion
  transformer = Transformer.from_proj(katech_proj, wgs84_proj)
  
  # Function to convert from KATECH (TM127) to WGS84
  def katech_to_wgs84(x, y):
      lon, lat = transformer.transform(x, y)
      return lat, lon
  ```
2) *유동인구 > x, y* 를 (1)의 함수에 넣은 후 도출된 결과를 각각 *유동인구 > latitude, longitude*에 넣기

</br>

#### (4) 필요없는 컬럼 삭제
- 'x', 'y' : 경위도로 변환 완료 (latitude, longitude로 대체)
- 'admi_cd' : 행정동명 컬럼 추가 완료 (행정동명으로 대체)
- 'total' : 연령대별 이동경로 및 소비패턴을 살펴볼 예정이므로 삭제

</br>
  
#### (5) "공휴일" 컬럼 추가
- 국가에서 지정한 공휴일
- holidays 패키지 활용
- 공휴일 아님 / 공휴일
</br>

1) *유동인구 > etl_ymd* 의 type을 datetime으로 변경
2) **holidays.KR()** 를 통해 한국 휴일 객체 생성
3) *유동인구 > etl_ymd* 데이터가 한국 휴일 객체에 존재하면 "공휴일", 그렇지 않으면 "공휴일 아님"을 *유동인구 > 공휴일* 컬럼에 추가


</br>

#### (6) "주말" 컬럼 추가
- *유동인구 > etl_ymd* 에서 파생
- 월요일 ~ 금요일 : 평일 / 토요일, 일요일 : 주말
- dayofweek 기능 활용
</br>

1) dayofweek 기능을 활용하여 5이상이면 주말, 4이하이면 평일로 반환하는 함수 정의 (0 : 월요일 ~ 6 : 일요일)
2) *유동인구 > etl_ymd* 를 해당 함수에 입력하여 *유동인구 > 주말* 컬럼 생성

</br>

#### (7) 연령대별 컬럼 합치기 : 10세 단위로
- 연령대를 10세 단위로 합쳐서 **10세 미만, 10대, 20대, 30대, 40대, 50대, 60대, 70대 이상**으로 만들기
- 10세 단위로 연령대를 합친 이유는 이후 이동경로 및 소비패턴 분석을 진행할 때 더욱 용이하기 때문
```
(왼쪽 : 기존 *유동인구* 컬럼명 | 오른쪽 : 합친 컬럼명)
- m00, f00 : m00, f00 
- m10 ~ m15, f10 ~ f15 : m10, f10 
- m20 ~ m25, f20 ~ f25 : m20, f20 
- m30 ~ m35, f30 ~ f35 : m30, f30 
- m40 ~ m45, f40 ~ f45 : m40, f40 
- m50 ~ m55, f50 ~ f55 : m50, f50 
- m60 ~ m65, f60 ~ f65 : m60, f60 
- m70, f70 : m70, f70 
```

</br>

#### (8) 전처리 완료 데이터 저장
- ***2.이동경로 분석*** 부터는 전처리 완료된 데이터를 불러와서 사용
- 전처리 완료 데이터 컬럼에 대한 설명은 *전처리완료데이터_컬럼정의서* 참고

</br>

---
### 1-2 카드매출_가맹점
#### (1) cell_id : 경위도 컬럼 추가
- 500m*500m 셀의 위치를 나타내는 컬럼
- 함께 주어진 ***국토지리정보원_국토조사_(격자)500M.csv***를 활용하여 경도/위도로 변환
- 순서는 아래 ①, ② 와 같음
##### ① *국토지리정보원_국토조사_(격자)500M.csv*
- x좌표, y좌표 : UTM-K 좌표 → 경위도 좌표(wsg84)로 변환  
- EPSG : 5178 = 중앙 경선이 127도가 되도록 하는 **대한민국 중앙부 기준**
</br>

1) 다음과 같은 좌표 변환 함수 정의
```
transformer = Transformer.from_crs("epsg:5178", "epsg:4326", always_xy=True)

# 위도와 경도로 변환하는 함수
def katec_to_wgs84(x, y):
    lon, lat = transformer.transform(x, y)
    return lon, lat
```
2) 1)에서 정의한 함수에 *국토지리정보원_국토조사_(격자)500M.csv > x좌표, y좌표*를 입력하여 반환된 값을 *국토지리정보원_국토조사_(격자)500M.csv > latitude, longitude* 컬럼에 추가

</br>

##### ② *카드매출_가맹점 > cell_id* 에 맵핑
- *카드매출_가맹점 > cell_id* 종류
  ```
    '다바88b09b', '다바88b10a', '다바89a09b', '다바89a10a', '다바89a10b',
     '다바89a11b', '다바89b09b', '다바89b10b', '다바89b11a', '다바89b11b',
     '다바89b12a', '다바89b12b', '다바89b13a', '다바89b13b', '다바90a10b',
     '다바90a11a', '다바90a11b', '다바90a12a', '다바90a12b', '다바90a13a',
     '다바90a13b', '다바90a14a', '다바90a14b', '다바90b08a', '다바90b08b',
     '다바90b10b', '다바90b11a', '다바90b12a', '다바90b12b', '다바90b13a',
     '다바90b13b', '다바90b14a', '다바90b14b', '다바90b15a', '다바91a11b',
     '다바91a12a', '다바91a12b', '다바91a13a', '다바91a13b', '다바91a14a',
     '다바91a14b', '다바91a15a', '다바91a15b', '다바91a16b', '다바91b11a',
     '다바91b12a', '다바91b12b', '다바91b13a', '다바91b13b', '다바91b14a',
     '다바91b14b', '다바91b15a', '다바91b15b', '다바91b16a', '다바91b16b',
     '다바92a12a', '다바92a12b', '다바92a13a', '다바92a13b', '다바92a14a',
     '다바92a14b', '다바92a15a', '다바92a15b', '다바92a16a', '다바92b04a',
     '다바92b12a', '다바92b12b', '다바92b13a', '다바92b13b', '다바92b14a',
     '다바92b14b', '다바92b15a', '다바92b15b', '다바93a12a', '다바93a12b',
     '다바93a13a', '다바93a13b', '다바93a14a', '다바93a14b', '다바93a15a',
     '다바93b12a', '다바93b12b', '다바93b13a', '다바93b13b', '다바93b14a',
     '다바93b14b', '다바94a12b', '다바94a13a', '다바94a13b', '다바94a14a',
     '다바94b12a', '다바94b12b', '다바94b13a', '다바95a11b', '다바95a12a',
     '다바95b11a', '다바95b11b', '다바96a11a', '다바90a08a', '다바91a10b',
     '다바88b09a', '다바94a12a', '다바95b10b', '다바90b11b', '다바91b08b',
     '다바94b11a', '다바95a11a', '다바91a08b', '다바92b02b', '다바91a16a',
     '다바91b05b', '다바89b08a', '다바91a08a', '다바92a02a', '다바94b11b',
     '다바92a01b', '다바89a11a', '다바91b11b', '다바89a09a', '다바90a07b',
     '다바92b01b', '다바95a12b', '다바91a05a', '다바94a11b', '다바92b09b',
     '다바90b09a', '다바96a10b', '다바90a08b', '다바93a05a'
  ```
</br>

1) *국토지리정보원_국토조사_(격자)500M*에서 '다바'를 포함하고 있는 cell_id 추출
2) *카드매출_가맹점 > cell_id*와 *국토지리정보원_국토조사_(격자)500M >격자 ID* 비교하여 위도, 경도를 반환하는 함수 정의
3) 해당 함수에 *카드매출_가맹점 > cell_id*를 넣어서 도출된 결과를 각각 *카드매출_가맹점 > latitude, longitude*에 추가

</br>

#### (2) 업종대분류, 업종중분류, 업종소분류
##### ① 결측치 : drop
- *카드매출_가맹점* 을 통해서 *업종소분류*를 파악하는 것이 중요하기 때문에 업종소분류가 결측치인 데이터는 모두 제외
- *업종소분류*의 결측치를 제거하면 *업종대분류, 업종중분류*의 결측치도 다함께 제거됨

</br>

##### ② 업종분류명 컬럼 추가
###### **방법[1]** ***상가(상권)정보_업종분류.xlsx*** 활용
- ***제공된 데이터 - sub*** 중 업종분류코드와 업종분류명이 표기돼 있는 데이터
- 그런데 해당 데이터는 *카드매출_가맹점*에 있는 모든 업종분류코드를 설명하고 있지 않음
```
카드매출_가맹점 > 업종대분류
 ['G' 'I' 'M' 'S' 'P' 'O' 'R' 'N' 'C' 'Q' 'H' 'J' 'K' 'L']

상가(상권)정보_업종분류 > 대분류코드
 ['G2' 'I1' 'I2' 'L1' 'M1' 'N1' 'P1' 'Q1' 'R1' 'S2']
```
- 따라서 업종분류명 컬럼을 추가할 때는 다음 **방법[2]**를 사용
</br>

###### **방법[2]** ***한국표준산업분류10차_표.xlsx***
- 외부 데이터인 ***통계청 한국표준산업분류10차(이하 산업분류10차)***(한국표준산업분류10차_표.xlsx) 활용
- *산업분류10차* 컬럼(왼쪽)과 *카드매출_가맹점 > 업종대분류, 업종중분류, 업종소분류*(오른쪽) 비교
  ```
    - 대분류(21) : 업종대분류
    - 중분류(77) : 업종중분류
    - 소분류(232) : (대응되는 컬럼 없음)
    - 세분류(495) : (대응되는 컬럼 없음)
    - 세세분류(1,196) : 업종소분류
  ```
</br>

1) *한국표준산업분류10차_표.xlsx > 소분류(232), 세분류(495)* 는 *카드매출_가맹점* 컬럼에 대응되지 않기 때문에 삭제
2) 이외 데이터는 다음과 같이 컬럼명 변경
```
[변경 전]
'코드', '항목명', '코드.1', '항목명.1', '코드.4', '항목명.4'

[변경 후]
'대분류_코드', '대분류_항목명','중분류_코드', '중분류_항목명', '소분류_코드', '소분류_항목명'
```
3) 대/중/소분류를 각각 {코드 : 항목명} 딕셔너리로 구성  
  e.g. {대분류_코드 : 대분류_항목명}
  ```
  {'A': '농업, 임업 및 어업(01~03)',
   'B': '광업(05~08)',
   'C': '제조업(10~34)',
   'D': '전기, 가스, 증기 및 공기 조절 공급업(35)',
   'E': '수도, 하수 및 폐기물 처리, 원료 재생업(36~39)',
   'F': '건설업(41~42)',
   'G': '도매 및 소매업(45~47)',
   'H': '운수 및 창고업(49~52)',
   'I': '숙박 및 음식점업(55~56)',
   'J': '정보통신업(58~63)',
   'K': '금융 및 보험업(64~66)',
   'L': '부동산업(68)',
   'M': '전문, 과학 및 기술 서비스업(70~73)',
   'N': '사업시설 관리, 사업 지원 및 임대 서비스업(74~76)',
   'O': '공공 행정, 국방 및 사회보장 행정(84)',
   'P': '교육 서비스업(85)',
   'Q': '보건업 및 사회복지 서비스업(86~87)',
   'R': '예술, 스포츠 및 여가관련 서비스업(90~91)',
   'S': '협회 및 단체, 수리 및 기타 개인 서비스업(94~96)',
   'T': '가구 내 고용활동 및 달리 분류되지 않은 자가 소비 생산활동(97~98)',
   'U': '국제 및 외국기관(99)'}
  ```
4) *카드매출_가맹점 > 업종소분류* 맨 앞에 붙어있는 알파벳을 제거
   - *카드매출_가맹점 > 소분류_코드*는 **수치형**인 것에 반해, *카드매출_가맹점 > 업종소분류*는 *업종대분류*의 문자가 맨 앞에 붙어서 **범주형**으로 처리
   - 이후 분석 시 문자형보다는 수치형이 용이하기 때문에 정규표현식을 활용하여 제거
   - 알파벳을 제외하고 남은 숫자 부분도 분류별로 고유한 값이기 때문에 알파벳을 제거해도 무관
  ```
  e.g. G47212 → 47212
  ```
5) 3.에서 정의된 딕셔너리를 *카드매출_가맹점 > 업종대분류, 업종중분류, 업종소분류* 에 맵핑
6) 맵핑 후 결측치 개수 : 0

</br>

#### (3) 전처리 완료 데이터 저장
- ***2.이동경로 분석*** 부터는 전처리 완료된 데이터를 불러와서 사용
- 전처리 완료 데이터 컬럼에 대한 설명은 *전처리완료데이터_컬럼정의서* 참고

</br>

---
### 1-3 카드매출_유입고객
#### (1) 시군구_상권, 광역시_상권 : drop
- *시군구_상권*에 존재하는 데이터 : 30140
- *광역시_상권*에 존재하는 데이터 : 30
</br>

- 두 컬럼은 각각 30140, 30만 존재하고 이는 대전 중구, 대전광역시임  
- 우리는 이미 해당 데이터가 대전광역시와 대전광역시 중구에 대한 것임을 알고 있기 때문에 해당 컬럼들은 제거

#### (2) 업종대분류, 업종중분류, 업종소분류
##### ① 결측치 : drop
- 결측치 개수가 동일한 컬럼
  - 업종중분류 & 업종소분류
  - 행정동_상권 & 업력
- 결측치 데이터 간의 관계
  > 업종대분류가 결측치일 때, 업종중분류 & 업종소분류도 모두 결측치  
    **→ 업종중분류/업종소분류 결측치 ⊃ 업종대분류 결측치**
  
  > 행정동_상권 & 업력이 결측치일 때, 업종중분류 & 업종소분류도 모두 결측치  
    **→ 업종중분류/업종소분류 결측치 ⊃ 행정동_상권 & 업력 결측치**
 
  **∴업종중분류/업종소분류 결측치 ⊃ 업종대분류 결측치, 행정동_상권 & 업력 결측치**  
    **= 업종중분류의 결측치 (=업종소분류의 결측치)만 지우면 관련 결측치가 한꺼번에 없어짐**
</br>

- *카드매출_유입고객*을 통해서 업종소분류를 파악하는 것이 중요하기 때문에 업종소분류가 결측치인 데이터는 모두 제외

</br>

##### ② 업종분류명 컬럼 추가
- *카드매출_가맹점*과 같은 방법으로 진행
  - 외부 데이터인 *한국표준산업분류10차_표.xlsx* 활용
  - *카드매출_유입고객 > 업종소분류* 앞에 붙은 알파벳을 제거함으로써 **수치형**으로 변경
  - {업종분류코드 - 업종분류명}으로 구성되어 있는 딕셔너리를 *업종대분류, 업종중분류, 업종소분류*에 맵핑
- 맵핑 후 결측치 개수 : 0

</br>

#### (3) 행정동_상권 : 행정동명 컬럼 추가
- *유동인구* 와 같은 방법으로 진행
  - 외부 데이터인 *KIKcd_H.20240801.xlsx* 활용
  - {행정동_상권 - 행정동명} 으로 구성되어있는 딕셔너리를 *행정동_상권*에 맵핑

</br>

#### (4) 시군구_유입, 추정소득구간, 신용등급구간 : 결측치 drop
- 해당 변수들은 결측치를 보간할 방법이 따로 없음
  > *시군구_유입*이 결측일 때, *추정소득구간*과 *신용등급구간*도 결측
  > *추정소득구간*과 *신용등급구간*는 결측값이 동일
  
  **∴*시군구_유입* 결측치 ⊃ *추정소득구간, 신용등급구간* 결측치**  
    **= *시군구_유입*의 결측치만 지우면 *추정소득구간, 신용등급구간* 결측치도 한꺼번에 없어짐**

</br>

#### (5) 연령, 성별 : 결측치 drop
- 해당 변수들 역시 결측치를 보간할 방법이 따로 없음
- 이후 분석에서 연령과 성별을 파악하는 것이 중요하기 때문에 결측치인 데이터는 모두 제거

</br>

#### (6) 이용건수
##### ① 이용건수_지역화폐, 이용건수_재난지원금, 이용건수_기타 : 결측치 0으로 채우기
- 결측치를 0으로 채웠을 때 다음과 같은 등식이 성립하므로 결측치를 0으로 보간
  **이용건수 = 이용건수_지역화폐 + 이용건수_재난지원금 + 이용건수_기타**

##### ② 이용건수_재난지원금 : drop
- 모든 행이 0이므로 컬럼 자체를 삭제

</br>

#### (7) 전처리 완료 데이터 저장
- ***2.이동경로 분석*** 부터는 전처리 완료된 데이터를 불러와서 사용
- 전처리 완료 데이터 컬럼에 대한 설명은 *전처리완료데이터_컬럼정의서* 참고
  
</br>

---
## 2 이동경로 분석
- 앞선 *1 데이터 전처리* 에서 언급한 바와 같이 이후부터는 **전처리 완료된 데이터**를 사용
- ***2 이동경로 분석, 3 소비패턴 분석*은 필요한 함수를 정의**한 후 **마지막에 이를 병렬처리**하는 형식으로 진행
### 2-1 성심당 위치 파악
- **중요 가정 : latitude, longitude는 cell의 중심점 위치이다**
- 따라서 성심당이 어떤 cell에 포함되는지 확인하기 위해서 **성심당 위도, 경도 ± 50m 반경에 있는 *유동인구_전처리_완료 > latitude, longitude* 좌표 찾기**
- 성심당 위도, 경도 중심점으로 잡아서 가장 가까운 *latitude, longitude* 값 추출
</br>

1) 구글맵 상 성심당의 좌표를 기준으로 성심당의 위도, 경도를 변수에 할당
2) ±25m 반경을 찾기 위해 25m를 위도, 경도 단위로 변환 → 25m = 0.000225도
3) 성심당 위도 ± 0.00045, 성심당 경도 ± 0.00045, 총 4개의 값을 각각 변수에 할당
4) 해당 범위에 포함되는 *유동인구_전처리_완료 > latitude, longitude* 좌표 추출
5) 추출된 성심당 후보지 중 성심당과 가장 가까운 거리에 있는 좌표 선택
</br>

**성심당 유동인구를 나타낼 수 있는 cell은 '60123258'번 cell**

</br>


### 2-2 이동경로
#### (1) 이동경로 분석 전, 필요한 변수 정리
- ***SUNG_SIM_DANG_ID* = 60123258** : 성심당 cell id
- ***SUNG_SIM_DANG_OPENING_HOUR* = 8** : 성심당 영업시작 시각
- ***SUNG_SIM_DANG_CLOSING_HOUR* = 21** : 성심당 영업종료 시각
  - 본래 영업종료 시각이 22시이나, **timeze_cd = 21는 21시 ~ 21시 59분 1시간 동안의 유동인구**를 의미하는 것이기 때문에 21시로 지정
- ***MAX_DISTANCE_KM* = 3** : 1시간동안 한 사람이 이동할 수 있는 최대 거리
  - 일반적으로 사람들은 보통 1시간에 4-5km 정도를 걷는다는 의학적 소견 (출처 : 서울삼성병원 https://www.samsunghospital.com/webzine/smcdmedu/308/webzine_308_2.html)
  - 그러나 현재 분석하고 있는 대상은 관광객이기 때문에 이보다 느리게 걷는다고 가정하고 최대 3km로 설정
- ***COSINE_SIMILARITY_THRESHOLD* = 0.8** : 코사인 유사도 임계값 (임계값을 넘는 위치를 다음 이동 장소 후보로 지정)
- ***age_gender_mapping***
  ```
  age_gender_mapping = {
    'm00': ('10세 미만', '남성'),
    'm10': ('10대', '남성'),
    'm20': ('20대', '남성'),
    'm30': ('30대', '남성'),
    'm40': ('40대', '남성'),
    'm50': ('50대', '남성'),
    'm60': ('60대', '남성'),
    'm70': ('70대이상', '남성'),
   
    'f00': ('10세 미만', '여성'),
    'f10': ('10대', '여성'),
    'f20': ('20대', '여성'),
    'f30': ('30대', '여성'),
    'f40': ('40대', '여성'),
    'f50': ('50대', '여성'),
    'f60': ('60대', '여성'),
    'f70': ('70대이상', '여성')
  }
  ```  
  - *유동인구_전처리_완료 > m00 ~ f70* 컬럼명을 위와 같이 연령과 성별로 나누어 딕셔너리에 저장
  - 이하 "집단"은 m00 ~ f70 각각을 의미하며, 총 16개의 집단으로 나누어 이동경로 분석 예정
</br>

1) 앞서 설명한 변수들을 각각 할당
2) *SUNG_SIM_DANG_ID*를 통해 성심당 유동인구를 파악하고 그들 중 timezn_cd가 *SUNG_SIM_DANG_OPENING_HOUR* 이상이고 *SUNG_SIM_DANG_CLOSING_HOUR* 이하인 데이터를 필터링하여 성심당 유동인구 데이터 생성 (*sungsimdang_visits* 변수에 할당)

</br>

#### (2) 거리 계산 함수 : geodesic 패키지 활용
- geodesic 패키지를 사용하여 두 장소 간 거리를 km로 반환
- geodesic이 Numba와 호환되지 않기 때문에 Numba 사용X

</br>

#### (3) 코사인 유사도 계산 함수
- 코사인 유사도 계산 공식을 함수화
- numba의 njit : Python의 동적 기능을 배제하고 네이티브 코드로 컴파일하여 실행 속도가 크게 향상
</br>

1) 첫번째 장소, 두번째 장소의 위도, 경도, 유동인구를 각각 벡터화 
2) 두 행렬의 내적을 각 벡터의 길이를 곱한 값으로 나누기
   ```
   (벡터1과 벡터2의 내적) / (벡터1의 norm) * (벡터2의 norm) 
   ```

</br>

#### (4) 성심당 방문 전후 경로 추적 함수
- **성심당 방문시간별 전후 방문 경로** 추적
  ```
  예시1) 성심당 12시 방문 → 0 ~ 11시 & 13시 ~ 23시 성심당 외 방문 장소 추적
  예시2) 성심당 13시 방문 → 0 ~ 12시 & 14시 ~ 23시 성심당 외 방문 장소 추적
  ```
- 성심당 방문시간 전후 **총 23시간의 방문 장소** 추출
- 따라서 하루 당 **성심당 영업시간대 14개(8시~21시) X 23시간 동안의 방문 장소**를 추적  
  → (14 * 23)개의 행 생성
  
</br>

(코드 진행과 일치하지 않지만, 실제 데이터가 처리되는 순서대로 설명)  
##### 1) 총 12개의 컬럼 생성 (하단의 분석 과정을 더 쉽게 이해하기 위해 *이동경로_소비패턴_컬럼정의서.xlsx* 를 먼저 읽을 것을 권장) **→ 하단 내용 필수적으로 숙지**
```
날짜 | 공휴일 | 주말 | 연령대 | 성별 | 성심당_유동인구 | 성심당_방문시간 | 전후_방문시간대 | 전후_방문장소_위도 | 전후_방문장소_경도 | 전후_방문장소_행정동명 | 이동거리(km)
```
   - 컬럼별 상세 설명
     ```
     [1] 날짜 : 성심당 방문 날짜 (YYYY-mm-dd)
     [2] 공휴일 : 성심당 방문 날짜의 공휴일 여부 (공휴일 / 공휴일 아님)
     [3] 주말 : 성심당 방문 날짜의 주말 여부 (주말 / 평일)
     [4] 연령대 : 성심당 방문 집단의 연령대 (10세 미만 ~ 70세 이상)
     [5] 성별 : 성심당 방문 집단의 성별 (남성 / 여성)
     [6] 성심당_유동인구 : 성심당을 방문한 시간의 성심당 유동인구
     [7] 성심당_방문시간 : 성심당을 방문한 시간 (8 ~ 21)
     [8] 전후_방문시간대 : 성심당 이전, 이후에 타 장소에 방문했던 시각 (0 ~ 23 중 성심당 방문시간 제외한 23시간)
     [9] 전후_방문장소_위도 : 성심당 이전, 이후에 방문했던 장소의 위도 
     [10] 전후_방문장소_경도 : 성심당 이전, 이후에 방문했던 장소의 경도
     [11] 전후_방문장소_행정동명 : 성심당 이전, 이후에 방문했던 장소의 행정동명
     [12] 이동거리(km) : t-1시에 방문한 장소와 t시에 방문한 장소 간의 거리
          → 전후_방문시간대 = 0 인 경우, '-' 처리 (0시부터 이동경로 분석을 시작하기 때문에 0시 이전 방문 장소와의 거리는 알 수 없음)
     ```
   - 이동경로는 다음과 같은 방식으로 분석됨
     ```
     - 성심당 8시 방문 : 0시 ~ 7시 & 9시 ~ 23시 방문 장소 추적
     - 성심당 9시 방문 : 0시 ~ 8시 & 10시 ~ 23시 방문 장소 추적
     - 성심당 10시 방문 : 0시 ~ 9시 & 11시 ~ 23시 방문 장소 추적
     - 성심당 11시 방문 : 0시 ~ 10시 & 12시 ~ 23시 방문 장소 추적
     - 성심당 12시 방문 : 0시 ~ 11시 & 13시 ~ 23시 방문 장소 추적
     - 성심당 13시 방문 : 0시 ~ 12시 & 14시 ~ 23시 방문 장소 추적
     - 성심당 14시 방문 : 0시 ~ 13시 & 15시 ~ 23시 방문 장소 추적
     - 성심당 15시 방문 : 0시 ~ 14시 & 16시 ~ 23시 방문 장소 추적
     - 성심당 16시 방문 : 0시 ~ 15시 & 17시 ~ 23시 방문 장소 추적
     - 성심당 17시 방문 : 0시 ~ 16시 & 18시 ~ 23시 방문 장소 추적
     - 성심당 18시 방문 : 0시 ~ 17시 & 19시 ~ 23시 방문 장소 추적
     - 성심당 19시 방문 : 0시 ~ 18시 & 20시 ~ 23시 방문 장소 추적
     - 성심당 20시 방문 : 0시 ~ 19시 & 21시 ~ 23시 방문 장소 추적
     - 성심당 21시 방문 : 0시 ~ 20시 & 22시 ~ 23시 방문 장소 추적
     ```
     
  - **(예시 필독)** e.g. 2023년 7월 1일 (공휴일 아님, 주말) 20대 여성 집단의 이동경로 데이터는 다음과 같은 과정으로 생성
     ```
     [1] 성심당 8시에 방문한 20대 여성 집단의 이동경로 : 성심당 유동인구 0이므로 *성심당_방문시간 ~ 이동거리(km)* 컬럼 '-' 처리
         - 날짜 : 2023-07-01
         - 공휴일 : 공휴일 아님
         - 주말 : 주말
         - 연령대 : 20대
         - 성별 : 여성
         - 성심당_유동인구 : 0
         - 성심당_방문시간 : -
         - 전후_방문시간대 : -
         - 전후_방문장소_위도 : -
         - 전후_방문장소_경도 : -
         - 전후_방문장소_행정동명 : -
         - 이동거리(km) : -
     
     [2] 성심당 9시에 방문한 20대 여성 집단이 0시에 방문한 장소에 대한 행
         - 날짜 : 2023-07-01
         - 공휴일 : 공휴일 아님
         - 주말 : 주말
         - 연령대 : 20대
         - 성별 : 여성
         - 성심당_유동인구 : 1.78
         - 성심당_방문시간 : 9
         - 전후_방문시간대 : 0 → 성심당 9시에 방문한 20대 여성 집단이 "0"시에 방문한 장소
         - 전후_방문장소_위도 : 36.32323445459926
         - 전후_방문장소_경도 : 127.39363155251102	
         - 전후_방문장소_행정동명 : 태평2동
         - 이동거리(km) : - → 0시부터 이동경로 분석을 시작하기 때문에 0시 이전 방문 장소와의 거리는 알 수 없음
  
     ...
     
     [10] 성심당 9시에 방문한 20대 여성 집단이 8시에 방문한 장소에 대한 행
         - 날짜 : 2023-07-01
         - 공휴일 : 공휴일 아님
         - 주말 : 주말
         - 연령대 : 20대
         - 성별 : 여성
         - 성심당_유동인구 : 1.78
         - 성심당_방문시간 : 9
         - 전후_방문시간대 : 8 → 성심당 9시에 방문한 20대 여성 집단이 "8"시에 방문한 장소
         - 전후_방문장소_위도 : 36.32239736429161
         - 전후_방문장소_경도 : 127.40644591679292		
         - 전후_방문장소_행정동명 : 오류동
         - 이동거리(km) : 0.40313639861145906 → "7"시에 방문한 장소와 현재("8"시에) 방문한 장소 간의 거리
  
     ...
   
     ```  

##### 2) 총 3개의 경우로 나누어 이동경로 분석
``` 
[1] 성심당 유동인구가 0인 경우
   - *날짜 ~ 성심당_방문시간* : 성심당 유동인구 데이터에서 추출
   - *전후_방문시간대 ~ 이동거리(km)* : '-'  
[2] 성심당 유동인구가 0이 아닌 경우
   - *날짜 ~ 이동거리(km)* : 성심당 유동인구 데이터에서 추출
```
- [1] : 이동경로 추적 X
- [2] : 이동경로 추적 O

##### 3) *성심당 유동인구가 0이 아닌 경우*, 즉 코드의 ***trace_route 함수*** 에 대한 코드 설명  
1. 데이터를 저장할 리스트 생성
2. 성심당을 현재 방문장소로 초기 설정  
    - 성심당 방문 데이터는 성심당 영업시간 동안의 유동인구 데이터  
    - 즉 앞서 *(1) 이동경로 분석 전, 필요한 변수 정리* 에서 정의한 8 ~ 21시의 성심당 유동인구 데이터 
3. 성심당 방문 '전'/'후' - 2가지 경우로 나누어서 분석  
  ```
   ① 성심당 방문 '전' 이동경로  
     - 성심당 방문 시간을 시작으로 역순으로 방문장소 추적  
       → range(visit_row['timezn_cd'] - 1, -1, -1)  
     - e.g. (성심당 12시 방문) → 11시 방문 장소 → 10시 방문 장소 → ... → 0시 방문 장소  

   ② 성심당 방문 '후' 이동경로  
     - 성심당 방문 시간을 시작으로 순서대로 방문장소 추적  
       → range(visit_row['timezn_cd'] + 1, 24)  
     - e.g. (성심당 12시 방문) → 13시 방문 장소 → 14시 방문 장소 → ... → 23시 방문 장소
  ```
4. **!!성심당 방문 '전' 이동경로의 "이동거리(km) 주의사항!!** (성심당 방문 '후' 이동경로는 해당X)
    - *이동거리(km)*은 본래 **이전 장소와의 거리**를 나타냄
    - 하지만, 코드 상의 메커니즘으로 계산하면 **"t-1시점 방문장소와 t-2시점 방문장소 간의 거리"가 "t-2시점 방문장소 행"에 추가됨**
    - 즉, 이전 장소와의 거리가 아니라 **"다음 장소와의 거리가 거리"가 기록됨**
    - 따라서 **"t-1시점 방문장소와 t-2시점 방문장소 간의 거리"는 "t-1시점 방문장소 행"에 기록될 수 있게 "이동거리(km)" 값은 리스트에 저장했다가 후처리**할 예정

5. 성심당 방문 전/후 이동경로 **공통 분석 과정** 
    - *(2) 거리 계산 함수 : geodesic 패키지 활용* 에서 정의한 *거리 계산 함수*로 이전 시간대 방문 장소와 현재 시간대의 모든 경위도 간의 거리 계산
    - *(1) 이동경로 분석 전, 필요한 변수 정리 > MAX_DISTANCE_KM = 3km* 를 넘지 않는 거리의 데이터만 필터링
    - *(3) 코사인 유사도 계산 함수* 를 통해 **이전 시간대 방문장소와 현재 시간대 장소들간의 코사인 유사도** 계산
    - 앞서 필터링된 데이터 중 *(1) 이동경로 분석 전, 필요한 변수 정리 > COSINE_SIMILARITY_THRESHOLD = 0.8*)을 넘으면서 코사인 유사도 값이 가장 큰 장소 찾기
      - 성심당 방문 "전" 이동경로의 이동거리는 *prev_next_distance* 리스트에 추가한 후 후처리
    - 앞서 설명한 컬럼 12개를 차례대로 추가
      - 이때, 성심당 방문 전 이동경로의 경우 후처리 예정이기 때문에 *이동거리(km)* 를 None으로 비워두기
      - 모든 컬럼 추가가 끝난 후, 성심당 방문 전 이동경로의 경우, prev_next_distance 리스트에 저장된 값을 다음 시간대의 "이동경로(km)" 컬럼에 삽입
      - 즉, prev_next_distance 리스트를 정의할 때 설명한 바와 같이 "t-1시점 방문장소와 t-2시점 방문장소 간의 거리"는 "t-1시점 방문장소 행"에 기록
     
</br>

#### (5) 병렬 처리를 적용할 함수
- **날짜별 > 집단(연령/성별)** 별 *(4) 성심당 방문 전후 경로 추적 함수* 실행

</br>

#### (6) 정의한 함수를 병렬 처리
- *유동인구 (원본)* 과 *유동인구_전처리_완료* 둘 다 용량이 10GB가 넘음
- 날짜별로 같은 작업을 수행하기 때문에 모든 날짜를 하나씩 처리하기보다는 병렬 처리
- 이를 위해 **jolbib** 라이브러리의 **Parallel, delayed** 클래스를 활용
</br>

1. 날짜별로 데이터 그룹화
2. Paralle(n_jobs=-1)로 설정함으로써 cpu 논리 프로세서 최대로 사용하여 병렬 처리되도록 함
3. 병렬 처리 후 결과를 flatten하여 통합
4. 결과를 데이터프레임으로 변환 → 이동경로는 ***df_movement*** 변수에 할당

</br>

  
## 3 소비패턴 분석
- 앞서 생성한 ***df_movement***에 컬럼 붙이는 형식으로 소비패턴 분석
### 3-1 데이터 전처리
1. *카드매출(가맹점)_전처리_완료.csv*, *카드매출(유입고객)_전처리_완료.csv* 를 각각 *industry_data, customer_data* 변수에 할당
2. *df_movement, industry_data, customer_data* 각각 날짜를 나타내는 컬럼을 datetime type으로 변환
3. 공공 행정 등을 포함하는 업종대분류 O는 제외 (우리의 타겟층이 아님)

</br>

### 3-2 컬럼 추가
- *df_movement*에 *industry_data*를 맵핑시키기 위해 *df_movement*에 *industry_data*같은 형식의 컬럼 생성
- 추가한 컬럼
  ```
  [1] 구분_시간대 : df_movement
      - 1 : 6-11시
      - 2 : 11-15시
      - 3 : 15-18시
      - 4 : 18-22시
      - 5 : 22-6시
  [2] 연령 : df_movement
      - 0 : 10세 미만
      - 1 : 10대
      - 2 : 20대
      - 3 : 30대
      - 4 : 40대
      - 5 : 50대
      - 6 : 60대, 70대 이상
  [3] 성별_숫자 : df_movement, industry_data
      - 0 : 남성
      - 1 : 여성
  [4] 구분_휴일평일 : : df_movement
      - 1 : 공휴일 또는 주말
      - 2 : 공휴일 아닌 평일
  [5] 업력_숫자 : industry_data
      - 1 : 1년 이하
      - 3 : 3년 이하
      - 5 : 5년 이하
      - 10 : 10년 이하
      - 15 : 10년 이상 → 10년 이상인 경우 "15"로 들어가게끔 했음
  [6] 날짜_숫자형 : df_movement, industry_data, customer_data
      - 앞서 *3-1 데이터 전처리*에서 datetime type으로 만든 날짜 형식의 컬럼들을 모두 "수치형"으로 변환
      - df_movement['날짜_숫자형'] : yyyymmdd
      - industry_data['기준일자_숫자형'] : yymmdd
      - customer_data['기준년월_numeric'] : yymm
  ```

</br>

### 3-3  이동경로 주변 업종 파악 : *카드매출_가맹점*을 통해
- **중요 가정** : *카드매출_가맹점*의 셀은 500m X 500m 격자의 중심점이다.  
#### (1) 각 cell_id 중심점에서의 위도, 경도 범위 계산 함수
- 이동경로와 마찬가지로 Numba 적용하여 처리 속도 개선
- 이동경로에 사용된 *유동인구*는 cell의 면적이 50m x 50m인 반면, *카드매출_가맹점*은 cell의 면적이 500m x 500m
- 따라서 *유동인구*의 셀을 포함하는 *카드매출_가맹점*의 셀을 필터링

</br>

#### (2) ***이동경로***에 ***카드매출_가맹점 > 업종소분류*** 를 맵핑하는 함수
-  *(1) 각 cell_id 중심점에서의 위도, 경도 범위 계산 함수*를 통해 **이동경로의 위치가 *카드매출_가맹점*의 어떤 cell**에 해당되는지 찾기
- 해당되는 cell에 기록되어있는 *카드매출_가맹점 > 업종소분류_코드, 업종소분류_항목명, 이용건수, 이용금액, 이용금액_지역화폐* 를 *이동경로* 데이터에 컬럼으로 붙이기
- 왼쪽 : *카드매출_가맹점*에서의 컬럼명 | 오른쪽 : *이동경로* 데이터에 추가한 컬럼명
  - 업종소분류 : 업종소분류_코드
  - 업종소분류_항목명 : 업종소분류_항목명
  - 이용건수 : 업종_일판매건수
  - 이용금액 : 업종_일매출
  - 이용금액_지역화폐 : 업종_일매출_지역화폐
</br>

- 3가지 경우로 나누어 분석 진행
  ```
  [1] df_movement > 성심당_유동인구 == 0
      - 추가될 모든 컬럼에 '-' 삽입
  [2]  *(1) 각 cell_id 중심점에서의 위도, 경도 범위 계산 함수*를 통해 필터링된 industry_data가 비어있을 경우
      - *df_movement > 전후_방문장소_위도, 전후_방문장소_경도*가 포함된 500m X 500m 셀에 해당 날짜에 업종 데이터가 없다는 의미
      - 따라서 추가될 모든 컬럼에 "주변 상권X" 삽입
  [3]  *(1) 각 cell_id 중심점에서의 위도, 경도 범위 계산 함수*를 통해 필터링된 industry_data가 채워져있을 경우 ([2]의 반대 경우)
      - 추가될 각 컬럼에 위에서 정의한 industry_data의 값을 삽입
  ```

</br>

#### (3) 정의한 함수를 날짜별로 병렬 처리
- *2-2 이동경로* 와 같은 과정의 병렬처리
- 날짜별 그룹화
- parallel(n_jobs= -1)을 통해 cpu 논리 프로세서 최대 개수 사용
- 결과 flatten
- ***result_df***라는 변수에 데이터프레임으로 할당

</br>

### 3-4 이동경로 주변 업종 중 해당 집단의 선호 업종 파악 : 카드매출_유입고객을 통해
- *카드매출_가맹점*으로 붙인 이동경로 주변 업종 중 해당 집단이 선호하는 업종을 파악하기 위해 *카드매출_유입고객*데이터 활용
- 업종을 단순 정렬하는 것이 아닌 **<< 연령 & 성별 & 방문 시간대 & 휴일/평일 & 날짜 >>** 별 유동인구 집단이 자주 가는 업종을 *이용건수 > 이용금액*을 기준으로 내림차순
- 위의 조건으로 *카드매출_유입고객*을 필터링했을 때 출력된 선호 업종과 일치하지 않는 이동경로 주변 업종은 "선호 업종X" 처리
- 단, 10세 미만의 경우 *카드매출_유입고객*에 기록된 데이터가 없기 때문에 '-' 처리
#### (1) 추가할 컬럼을 위한 계산 함수
- 수치 연산을 최적화하기 위해 Numba 적용
- 추가할 컬럼 : 평균_업력, 고객_타지역_비율, 고객_월이용건수, 고객_월이용금액
- 각각 다음과 같이 계산 (데이터는 (2)에서 필터링될 예정)
  ```
  - 평균_업력 : *필터링된 데이터 > 업력* 의 평균
  - 고객_타지역_비율 : *필터링된 데이터 > 광역시_유입* 이 30이 아닌, 즉 대전광역시가 아닌 데이터의 비율
  - 고객_월이용건수 : *필터링된 데이터 > 이용건수*의 합
  - 고객_월이용금액 : *필터링된 데이터 > 이용금액*의 합
  ```

</br>

#### (2) 이동경로 주변 업종 중 **해당 집단의 선호 업종** 순으로 정렬
- *카드매출_유입고객* 은 고객의 월 소비 데이터를 담고 있기 때문에 특정 집단(연령/성별)의 사람들이 한 달 동안 며칠 몇시 즈음에 어떤 업종에서 얼만큼을 소비했는 지 알 수 있음
- 따라서 앞서 3-3 에서 추가한 이동경로 주변 업종을 지금과 같은 **무작위 상태로 두는 것이 아니라 해당 집단의 사람들이 한 달 동안 소비가 많았던 순**으로 정렬
- 다음 3가지의 경우로 나눠서 분석 진행
  ```
  [1] "-"
      - *전후_방문장소_경도 == '-'* : 유동인구가 없는 경우에는 정렬할 업종이 없음  
      - *연령 == 0* :  10세미만은 *카드매출_유입고객* 에 데이터 존재하지 않기 때문에 제외  
      - *업종소분류_코드 == '주변 상권X'* : 이돋경로 주변에 업종이 존재하지 않기 때문에 정렬할 업종이 없음

  [2] "월 방문 업종X"
      - 이동경로 주변에 업종은 존재하지만, 즉 *카드매출_가맹점*에는 존재하는 업종이지만 집단, 날짜, 시간대별로 필터링된 *카드매출_유입고객*에는 해당 업종이 없는 경우
  
  [3] (정렬)
      - 이동경로 주변 업종이 집단, 날짜, 시간대별로 필터링된 *카드매출_유입고객*에도 존재하는 경우, 총 이용건수 > 총 이용금액이 높은 순으로 정렬  
      - 총 이용건수가 같은 경우 총 이용금액이 높은 순으로 정렬
  ```
</br>

1. <연령 & 성별 & 방문 시간대 & 휴일/평일 & 월> 조건에 맞는 *customer_data* 추출
2. 필터링된 *customer_data* 에서 총 이용건수 > 총 이용금액이 높은 순으로 정렬
3. *result_df > 업종소분류* 정렬할 리스트 생성
   ```
   [1] 3-3에서 추가한 업종 (*카드매출_가맹점* 500m 셀 안에 있는 모든 업종)
   [2] 2. 에서 정렬한 *카드매출_유입고객 > 업종소분류* 리스트
   [3] [1]에 있는 [2]는 정렬된 순서대로 리스트에 저장
       즉, 이동경로 주변 업종 중 고객이 방문한 업종을 이용건수가 높은 순서대로 리스트에 저장
   [4] [1]에 없는 [2]는 순서 고려하지 않고 리스트에 저장
        즉, 이동경로 주변 업종이지만, 해당 집단의 고객이 한 달동안 그 시간에 방문하지 않은 업종을 리스트에 저장
   [5] 고객이 방문한 업종을 이용건수가 높은 순서대로 저장한 리스트와 고객이 한 달동안 방문하지 않은 업종을 저장한 리스트를 하나로 합치기
       즉, 데이터 프레임 상단에는 고객이 방문한 업종을 이용건수가 높은 순서대로, 하단에는 방문하지 않은 업종이 나타나도록 *final_sorted_data* 리스트 생성
   ```
4. *final_sorted_data*의 요소가 *카드매출_유입고객*에 존재하는 업종인지 하나씩 필터링 (for문)
   - remaining_data에 저장돼있던 업종은 *카드매출_유입고객*에 존재X → empty 처리 됨
     → 추가될 모든 컬럼에 "월 방문 업종X" 삽입
   - ordered_data에 저장돼있던 업종은 *카드매출_유입고객*에도 존재
     → 추가될 컬럼에 *(1) 추가할 컬럼을 위한 계산 함수*의 값을 삽입
5. *result_df*에 *업종소분류*라는 컬럼을 새로 만들어서 *final_sorted_data* 데이터 삽입
6. *result_df > 업종소분류_코드*를 인덱스로 만든 후, *업종소분류*를 기준으로 정렬한 데이터를 ***result*** 라는 변수에 할당
7. 앞서 정리한 *years_mean, area_ratio, count_list, money_list*를 ***result > 평균_업력, 고객_타지역_비율, 고객_월이용건수, 고객_월이용금액*** 이라는 새로운 컬럼에 각각 추가

</br>

#### (3) 정의한 함수를 날짜별로 병렬 처리
- *2-2 이동경로* 와 같은 과정의 병렬처리
- 날짜별 그룹화
- parallel(n_jobs= -1)을 통해 cpu 논리 프로세서 최대 개수 사용
- 결과 flatten
- ***result_total***ㅇㅇ라는 변수에 데이터프레임으로 할당

</br>

---
## 4 이동경로 및 소비패턴 데이터 저장
- 이동경로에 따른 소비패턴이 붙어있는 데이터 ***result_total***를 csv로 저장
- **주의할 점 : 해당 데이터는 하나의 이동경로 값에 여러 개의 소비패턴이 붙어있음**
  즉, 여러 행 동안 소비패턴 값만 변화하고 이동경로 값은 반복될 수 있음 (한 장소에 여러 업종이 존재함을 데이터로 표현했기 때문)
  ```
  - 이동경로 컬럼
    날짜 | 공휴일 | 주말 | 연령대 | 성별 | 성심당_유동인구 | 성심당_방문시간 | 전후_방문시간대 | 전후_방문장소_위도 | 전후_방문장소_경도 | 전후_방문장소_행정동명 | 이동거리(km)
  - 소비패턴 컬럼
    업종소분류_코드 | 업종소분류_항목명 | 업종_일판매건수 | 업종_일매출 | 업종_일매출_지역화폐 | 평균_업력 | 고객_타지역_비율 | 고객_월이용건수 | 고객_월이용금액
  ```
- **가독성을 확보하기 위해 엑셀 파일(xlsx)로 저장하려 했으나, 용량이 큰 관계로 csv로 제출. 따라서 csv 파일을 해석할 때 위 내용 참고**

</br>

---
# 4.빵해장_이동경로 및 소비패턴 파일_컬럼 정의서.xlsx
- 데이터셋명 : 성심당_이동경로_소비패턴
- 파일명 : 성심당_이동경로_소비패턴.csv
- 순번 : 컬럼 정의 순서
- 속성 : 해당 데이터의 컬럼명
- 설명 : 데이터 컬럼에 대한 설명
- 값 범위 혹은 범주 : 각각 컬럼이 가지는 범위 혹은 범주
- 출처 데이터 > 컬럼명(전처리된 데이터 기준) : 전처리한 데이터로부터 사용된 컬럼명


---
# 5.빵해장_자유분석.pdf : 타겟별 여행지 추천 및 정책적 제안
**자세한 사항은 ***빵해장_자유분석.pdf*** 파일 참고**
## 5-1 대전광역시 여행 현황
- 성심당에 편중된 대전광역시 방문객들의 관광 양상
- 압도적인 개별 여행 비중
- 압도적인 당일 여행 비중
  
## 5-2 전제조건
- 현지인이 아닌 타 지역 거주자 방문
- 방문 시점 일반화
- 축제 vs 비축제

## 5-3 타겟별 분석
- 타겟 설정 배경
- 타겟별로 이동경로 및 소비패턴 분석 (QGIS를 통해 시각화)
- QGIS 및 AHP 가중치를 활용한 타겟별 관광 입지 선정 (QGIS를 통해 시각화)
  
## 5-4 제안
- 타겟별 실제 이동 경로와 AHP 결과의 비교를 통한 타겟별 전략 분석 및 여행지 추천, 홍보 방안 사례
- 비활성 상권 개선
- SNS 이벤트를 통한 홍보
 
</br>

---
# 6.figures
## 6-1 카드뉴스
자유분석 부분의 제안에서 타겟별로 추천하는 여행 코스에 대한카드 뉴스에 대한 파일 (가족편, 커플편, MZ편)

## 6-2 QGIS 캡쳐 사진
- QGIS 캡쳐 사진으로 제출된 파일든은 빵해장_자유분석의 [그림7.]부터 [그림36.]까지 해당하는 캡쳐 사진들의 원본 png 파일
- QGIS 캡쳐 사진으로 제출된 파일은 크게 세 종류로 분류가 됨
  1) QGIS_(날짜)_(나이대).png (Eg. QGIS_0505_10세미만.png)
  2) QGIS_타겟_(타겟).png (Eg. QGIS_타겟_가족.png)
  3) QGIS_대전

- QGIS_(날짜)_(나이대).png의 파일들에 설명은 다음과 같음
  ```
  - 날짜는 해당하는 날짜(12월25일, 5월5일, 8월12일, 2월17일, 7월8일)에서 각 나이대별로(10세미만, 10대, 20대, 30대, 40대, 50대) 성심당 유동인구가 제일 높은 시간대 기준 전후 시간대(8시~23시)의 경도, 위도를 매핑한 결과
  - 10세미만, 10대, 40대, 50대는 '가족', 20대와 30대는 '커플/MZ'로 분류하여 시각화를 진행하였으며, 버퍼 선택과 행정동 스코어 컬러링도 이에 맞춰 시각화를 진행하였다.
  - 남성은 삼각형을, 여성은 원을 사용하여 한 그림에 표시를 해두었다. 이때, 표시되는 점들은 해당하는 날짜의 성별의 해당 나이대의 각 전후 시간대별로 경도, 위도를 매핑한 것임을 재차 강조
  ``


- [QGIS_타겟_(타겟).png]의 파일들에 설명은 다음과 같음
  - 타겟별(공통, 커플, MZ, 가족)별 선정 변수와 해당 변수대로 AHP 스코어링 및 해당 점수 기반 행정동 스코어링과 버퍼 생성 과정을 시각화한 결과
  - 공통 변수로는 성심당, 대전 중구 유천시장, 뿌리공원, 숙소 개수가 선택됨
  - 공통에 사용된 변수는 나머지 변수들에 공통으로 사용될 변수임
  - 커플 변수로는 대전 스카이로드, 중구 맛집 개수, 대흥동 카페 개수가 선택됨
  - MZ 변수로는 보문산 전망대, 중구 중앙역 근처 현지인 맛집 개수, 은행동 오래된 맛집 개수가 선택됨
  - 가족 변수로는 대전오원드, 대전 근현대사 전시관,, 중구 맛집 개수, 주유소 개수가 선택됨
  - 변수별로 시각화 방법은 [방법1] 및 [방법2]로 나뉜다. *자세한 내용은 '빵해장_자유분석'을 참고

- QGIS_대전은 지오서비스를 활용하여 QGIS에서 대전, 대전 중구, 대전 중구 내의 행정동을 매핑한 결과물 파일
